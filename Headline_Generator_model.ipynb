{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Headline_Generator_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-47jSvJtgL7i",
        "outputId": "e1e3a977-0c1e-4f22-8740-0d5b114d5776"
      },
      "source": [
        "# Unzip the folder of articles\n",
        "from zipfile import ZipFile\n",
        "articles = (\"articles.zip\")\n",
        "\n",
        "with ZipFile(articles, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMNzHQS05w99",
        "outputId": "dbb25270-f244-41d0-857a-860c0e9286ef"
      },
      "source": [
        "# Reading the data \n",
        "import os \n",
        "import pandas as pd\n",
        "\n",
        "nyt_dir = 'articles/'\n",
        "\n",
        "all_headlines = []\n",
        "for filename in os.listdir(nyt_dir):\n",
        "    if 'Articles' in filename:\n",
        "        # Read in all the data from the CSV file\n",
        "        headlines_df = pd.read_csv(nyt_dir+filename)\n",
        "        # Add all of the headlines to our list\n",
        "        all_headlines.extend(list(headlines_df.headline.values))\n",
        "len(all_headlines)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9335"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-27sUpK67br",
        "outputId": "71692140-8e76-4173-b1e2-ab0b6c67043f"
      },
      "source": [
        "all_headlines[:20]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The Opioid Crisis Foretold',\n",
              " 'The Business Deals That Could Imperil Trump',\n",
              " 'Adapting to American Decline',\n",
              " 'The Republicans’ Big Senate Mess',\n",
              " 'States Are Doing What Scott Pruitt Won’t',\n",
              " 'Fake Pearls, Real Heart',\n",
              " 'Fear Beyond Starbucks',\n",
              " 'Variety: Puns and Anagrams',\n",
              " 'E.P.A. Chief’s Ethics Woes Have Echoes in His Past',\n",
              " 'Where Facebook Rumors Fuel Thirst for Revenge',\n",
              " 'The House Next Door Is an Airbnb. Here’s What You Can Do About It.',\n",
              " 'Punch the Air',\n",
              " 'Caution, Babies Voting',\n",
              " 'Childbirth’s Dangers for Black Women',\n",
              " 'A Man Set Himself on Fire. We Barely Noticed.',\n",
              " 'Why Men Quit and Women Don’t',\n",
              " 'Jewish Power At 70 Years',\n",
              " 'Here to Help; A Word on Phrasing: ‘Just Deserts’',\n",
              " 'It’s Curtains for ‘Gypsy’',\n",
              " 'The Endless Search for a Lost Glove']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNI5jEwR7BML",
        "outputId": "7ded394e-16fe-4876-c57b-ce4730903a53"
      },
      "source": [
        "# Cleaning the data\n",
        "# Remove all headlines with the value of \"Unknown\"\n",
        "all_headlines = [h for h in all_headlines if h != \"Unknown\"]\n",
        "len(all_headlines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8603"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgyPItf57Ejd",
        "outputId": "debbca2b-3bfe-4aaa-a413-6e21ba0300eb"
      },
      "source": [
        "all_headlines[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The Opioid Crisis Foretold',\n",
              " 'The Business Deals That Could Imperil Trump',\n",
              " 'Adapting to American Decline',\n",
              " 'The Republicans’ Big Senate Mess',\n",
              " 'States Are Doing What Scott Pruitt Won’t',\n",
              " 'Fake Pearls, Real Heart',\n",
              " 'Fear Beyond Starbucks',\n",
              " 'Variety: Puns and Anagrams',\n",
              " 'E.P.A. Chief’s Ethics Woes Have Echoes in His Past',\n",
              " 'Where Facebook Rumors Fuel Thirst for Revenge',\n",
              " 'The House Next Door Is an Airbnb. Here’s What You Can Do About It.',\n",
              " 'Punch the Air',\n",
              " 'Caution, Babies Voting',\n",
              " 'Childbirth’s Dangers for Black Women',\n",
              " 'A Man Set Himself on Fire. We Barely Noticed.',\n",
              " 'Why Men Quit and Women Don’t',\n",
              " 'Jewish Power At 70 Years',\n",
              " 'Here to Help; A Word on Phrasing: ‘Just Deserts’',\n",
              " 'It’s Curtains for ‘Gypsy’',\n",
              " 'The Endless Search for a Lost Glove']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvDD_hfi7IMz",
        "outputId": "2f56ba96-e2eb-4cd2-84cd-af3bc097fa91"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Tokenize the words in our headlines\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(all_headlines)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print('Total words: ', total_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total words:  11753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If9lA2a47NkY",
        "outputId": "1bfb0c79-94ec-4de8-a8b7-4bc963df4c15"
      },
      "source": [
        "# Print a subset of the word_index dictionary created by Tokenizer\n",
        "subset_dict = {key: value for key, value in tokenizer.word_index.items() \\\n",
        "               if key in ['a','man','a','plan','a','canal','panama']}\n",
        "print(subset_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'a': 2, 'plan': 82, 'man': 137, 'panama': 3200, 'canal': 11469}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbwubnAq7SDJ",
        "outputId": "d21d7647-cae3-48ed-ae51-41f5bd412f6a"
      },
      "source": [
        "tokenizer.texts_to_sequences(['a','man','a','plan','a','canal','panama'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2], [137], [2], [82], [2], [11469], [3200]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIys5gsG7VY5",
        "outputId": "fa60baf2-3c7a-4c23-c236-8ad4da05f1d8"
      },
      "source": [
        "# Creating sequences\n",
        "# Convert data to sequence of tokens \n",
        "input_sequences = []\n",
        "for line in all_headlines:\n",
        "    # Convert our headline into a sequence of tokens\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    \n",
        "    # Create a series of sequences for each headline\n",
        "    for i in range(1, len(token_list)):\n",
        "        partial_sequence = token_list[:i+1]\n",
        "        input_sequences.append(partial_sequence)\n",
        "\n",
        "print(tokenizer.sequences_to_texts(input_sequences[:5]))\n",
        "input_sequences[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the opioid', 'the opioid crisis', 'the opioid crisis foretold', 'the business', 'the business deals']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 1380], [1, 1380, 203], [1, 1380, 203, 2514], [1, 486], [1, 486, 822]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqB_obRC7akq",
        "outputId": "5a97f0d3-ffe3-4e0a-866a-2ed0a6e3fc02"
      },
      "source": [
        "# Padding Sequences\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Determine max sequence length\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "# Pad all sequences with zeros at the beginning to make them all max length\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "input_sequences[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    1, 1380], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBzRiXDT7dax",
        "outputId": "c10af820-44b0-4268-d230-ff8c5ed31fa5"
      },
      "source": [
        "# Predictors are every word except the last\n",
        "predictors = input_sequences[:,:-1]\n",
        "\n",
        "# Labels are the last word\n",
        "labels = input_sequences[:,-1]\n",
        "labels[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1380,  203, 2514,  486,  822], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klm-ajRt7gZ6"
      },
      "source": [
        "from tensorflow.keras import utils\n",
        "\n",
        "labels = utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OFB-AVo7jWA"
      },
      "source": [
        "# Creating the model\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Input is max sequence length - 1, as we've removed the last word for the label\n",
        "input_len = max_sequence_len - 1 \n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Add input embedding layer\n",
        "model.add(Embedding(total_words, 10, input_length=input_len))\n",
        "\n",
        "# Add LSTM layer with 100 units\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "# Add output layer\n",
        "model.add(Dense(total_words, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwfU4nAy7mCD"
      },
      "source": [
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ossh2kkz7oZz",
        "outputId": "30722641-94b1-4db7-fa8f-aabf89914df9"
      },
      "source": [
        "# Training the model\n",
        "model.fit(predictors, labels, epochs=30, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1666/1666 [==============================] - 66s 38ms/step - loss: 7.8930\n",
            "Epoch 2/30\n",
            "1666/1666 [==============================] - 63s 38ms/step - loss: 7.4858\n",
            "Epoch 3/30\n",
            "1666/1666 [==============================] - 62s 37ms/step - loss: 7.3043\n",
            "Epoch 4/30\n",
            "1666/1666 [==============================] - 62s 37ms/step - loss: 7.0935\n",
            "Epoch 5/30\n",
            "1666/1666 [==============================] - 62s 37ms/step - loss: 6.8613\n",
            "Epoch 6/30\n",
            "1666/1666 [==============================] - 63s 38ms/step - loss: 6.6147\n",
            "Epoch 7/30\n",
            "1666/1666 [==============================] - 62s 37ms/step - loss: 6.3639\n",
            "Epoch 8/30\n",
            "1666/1666 [==============================] - 62s 37ms/step - loss: 6.1132\n",
            "Epoch 9/30\n",
            "1666/1666 [==============================] - 62s 37ms/step - loss: 5.8668\n",
            "Epoch 10/30\n",
            "1666/1666 [==============================] - 63s 38ms/step - loss: 5.6330\n",
            "Epoch 11/30\n",
            "1666/1666 [==============================] - 63s 38ms/step - loss: 5.4096\n",
            "Epoch 12/30\n",
            "1666/1666 [==============================] - 63s 38ms/step - loss: 5.2028\n",
            "Epoch 13/30\n",
            "1666/1666 [==============================] - 62s 37ms/step - loss: 5.0003\n",
            "Epoch 14/30\n",
            "1666/1666 [==============================] - 64s 38ms/step - loss: 4.8085\n",
            "Epoch 15/30\n",
            "1666/1666 [==============================] - 63s 38ms/step - loss: 4.6331\n",
            "Epoch 16/30\n",
            "1666/1666 [==============================] - 62s 37ms/step - loss: 4.4662\n",
            "Epoch 17/30\n",
            "1666/1666 [==============================] - 63s 38ms/step - loss: 4.3047\n",
            "Epoch 18/30\n",
            "1666/1666 [==============================] - 62s 37ms/step - loss: 4.1534\n",
            "Epoch 19/30\n",
            "1666/1666 [==============================] - 62s 37ms/step - loss: 4.0153\n",
            "Epoch 20/30\n",
            "1666/1666 [==============================] - 63s 38ms/step - loss: 3.8803\n",
            "Epoch 21/30\n",
            "1666/1666 [==============================] - 62s 37ms/step - loss: 3.7587\n",
            "Epoch 22/30\n",
            "1666/1666 [==============================] - 63s 38ms/step - loss: 3.6390\n",
            "Epoch 23/30\n",
            "1666/1666 [==============================] - 63s 38ms/step - loss: 3.5338\n",
            "Epoch 24/30\n",
            "1666/1666 [==============================] - 63s 38ms/step - loss: 3.4279\n",
            "Epoch 25/30\n",
            "1666/1666 [==============================] - 62s 37ms/step - loss: 3.3338\n",
            "Epoch 26/30\n",
            "1666/1666 [==============================] - 62s 37ms/step - loss: 3.2398\n",
            "Epoch 27/30\n",
            "1666/1666 [==============================] - 62s 37ms/step - loss: 3.1564\n",
            "Epoch 28/30\n",
            "1666/1666 [==============================] - 62s 37ms/step - loss: 3.0811\n",
            "Epoch 29/30\n",
            "1666/1666 [==============================] - 62s 37ms/step - loss: 3.0048\n",
            "Epoch 30/30\n",
            "1666/1666 [==============================] - 62s 37ms/step - loss: 2.9339\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0f686b1050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1iKGSzz7r-x"
      },
      "source": [
        "# Making the predictions\n",
        "def predict_next_token(seed_text):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    prediction = model.predict_classes(token_list, verbose=0)\n",
        "    return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeJ0qBhg7w6X",
        "outputId": "68e1aae5-f2c1-4cc3-88e4-7c651d48d779"
      },
      "source": [
        "prediction = predict_next_token(\"today in new york\")\n",
        "prediction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([73])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Anj1jrrD7yxb",
        "outputId": "290cdd01-3e11-4e24-fecc-6c45c4d8c7e5"
      },
      "source": [
        "# tokenizer to decode the predicted word\n",
        "tokenizer.sequences_to_texts([prediction])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['today']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP2aQkFY70-L"
      },
      "source": [
        "# Generate new headlines\n",
        "# function that can predict headlines of more than just one word\n",
        "\n",
        "def generate_headline(seed_text, next_words=1):\n",
        "    for _ in range(next_words):\n",
        "        # Predict next token\n",
        "        prediction = predict_next_token(seed_text)\n",
        "        # Convert token to word\n",
        "        next_word = tokenizer.sequences_to_texts([prediction])[0]\n",
        "        # Add next word to the headline. This headline will be used in the next pass of the loop.\n",
        "        seed_text += \" \" + next_word\n",
        "    # Return headline as title-case\n",
        "    return seed_text.title()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKO3DDCn73CB",
        "outputId": "174719da-4117-4603-acfa-769c7a4c6442"
      },
      "source": [
        "# Try some headlines\n",
        "\n",
        "seed_texts = [\n",
        "    'washington dc is',\n",
        "    'today in new york',\n",
        "    'the school district has',\n",
        "    'crime has become']\n",
        "for seed in seed_texts:\n",
        "    print(generate_headline(seed, next_words=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Washington Dc Is Capitalism The Mainstream I Looks\n",
            "Today In New York Today A Costlier Commute Off\n",
            "The School District Has The Lives Of Master Of\n",
            "Crime Has Become The Description Right To Be\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}